{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Add, Dropout, Concatenate, Embedding, Bidirectional, LSTM, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from models import InferSent\n",
    "import torch\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import datetime\n",
    "np.random.seed(3252) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "The following data set is formed from the combination of the datasets:\n",
    "- https://github.com/clinc/oos-eval [\"An Evaluation Dataset for Intent Classification and Out-of-Scope Prediction\" (EMNLP 2019) ]\n",
    "- NLU Dataset Benchmarking Natural Language Understanding Services for building Conversational Agents(https://arxiv.org/abs/1903.05566). The NLU dataset was combined by looking at the answer, scenario + intent\n",
    "- \"Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces\"https://github.com/snipsco/nlu-benchmark/tree/master/2017-06-custom-intent-engin - found from deep.pavlov website\n",
    "\n",
    "## Other Datasets considered\n",
    "- https://voice.mozilla.org/en/datasets\n",
    "Conversation Corpus:\n",
    "https://www.clarin.eu/resource-families/spoken-corpora\n",
    "https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "https://www.aclweSpoken corporab.org/anthology/D18-1305.pdf\n",
    "https://www.linguistics.ucsb.edu/research/santa-barbara-corpus\n",
    "https://neurohive.io/en/datasets/natural-questions-new-large-scale-corpus-for-question-answering-by-google-ai/\n",
    "https://arxiv.org/abs/1506.08909 - stanford multi turn dataset\n",
    "\n",
    "However, these datasets haven't been processed and labeled by intents unlike the other datasets we selected. If the training is lacking, we can probalby probably speech to text and label some data. These datasets are also good for testing\n",
    "\n",
    "## Intents \n",
    "222 different intents. View `intent_counts.csv` to see full list of intents and counts. \n",
    "There are a total of 64174 lines of text in the combined dataset.\n",
    "\n",
    "### None Type Intent Classification\n",
    "TODO: Add More oos(Out of scope queries) that handle queries that are bad. One suggestion was to put Movie Subtitles Dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intents</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PlayMusic</th>\n",
       "      <td>2300</td>\n",
       "      <td>3.584565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetWeather</th>\n",
       "      <td>2300</td>\n",
       "      <td>3.584565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookRestaurant</th>\n",
       "      <td>2273</td>\n",
       "      <td>3.542485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SearchScreeningEvent</th>\n",
       "      <td>2259</td>\n",
       "      <td>3.520666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RateBook</th>\n",
       "      <td>2256</td>\n",
       "      <td>3.515990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interest_rate</th>\n",
       "      <td>150</td>\n",
       "      <td>0.233776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>international_fees</th>\n",
       "      <td>150</td>\n",
       "      <td>0.233776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>international_visa</th>\n",
       "      <td>150</td>\n",
       "      <td>0.233776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jump_start</th>\n",
       "      <td>150</td>\n",
       "      <td>0.233776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>150</td>\n",
       "      <td>0.233776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count      prop\n",
       "intents                              \n",
       "PlayMusic              2300  3.584565\n",
       "GetWeather             2300  3.584565\n",
       "BookRestaurant         2273  3.542485\n",
       "SearchScreeningEvent   2259  3.520666\n",
       "RateBook               2256  3.515990\n",
       "...                     ...       ...\n",
       "interest_rate           150  0.233776\n",
       "international_fees      150  0.233776\n",
       "international_visa      150  0.233776\n",
       "jump_start              150  0.233776\n",
       "yes                     150  0.233776\n",
       "\n",
       "[222 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_counts = df.groupby(['intents']).size().to_frame('count') # df.groupby(['intents']).count().to_csv('intent_counts.csv')\n",
    "intent_counts = intent_counts.sort_values('count', ascending=False)\n",
    "\n",
    "total_count = intent_counts[\"count\"].sum()\n",
    "intent_counts[\"prop\"] = intent_counts[\"count\"]/total_count * 100\n",
    "# intent_counts.to_csv('intent_counts.csv')\n",
    "intent_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the datasets\n",
    "\n",
    "# CLINC150 dataset/oos-eval dataset Preprocessing\n",
    "```python\n",
    "with open('oos-eval/data/data_full.json', 'r') as f:\n",
    "    oos_eval_dataset = json.load(f)\n",
    "    out_of_scope = oos_eval_dataset[\"oos_val\"]\n",
    "    in_scope_labels = oos_eval_dataset[\"val\"]\n",
    "    train = oos_eval_dataset[\"oos_train\"]\n",
    "df = pd.DataFrame(train, columns=['text', 'intents'])\n",
    "df = df.where(df['intents'] == 'oos').append(pd.DataFrame(out_of_scope, columns=['text', 'intents']), ignore_index=True)\n",
    "data.extend(list(df.T.to_dict().values()))\n",
    "```\n",
    "\n",
    "# NLU Dataset\n",
    "```python\n",
    "nlu_dataset = pd.read_csv('NLU-Evaluation-Data/Collected-Original-Data/paraphrases_and_intents_26k_normalised_all.csv', delimiter=';')\n",
    "nlu_dataset = nlu_dataset[[\"answer_normalised\", \"scenario\", \"intent\", \"suggested_entities\"]]\n",
    "nlu_dataset[\"full_intent\"] = nlu_dataset[\"scenario\"] + nlu_dataset[\"intent\"].str.title() \n",
    "nlu_dataset = nlu_dataset[[\"answer_normalised\", \"full_intent\"]]\n",
    "nlu_dataset.columns = [\"text\", \"intents\"]\n",
    "nlu_dataset = nlu_dataset.iloc[:, ::-1]\n",
    "df = df.append(nlu_dataset, ignore_index=True)\n",
    "df.to_json('test2.json', orient='records')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Classifiers\n",
    "\n",
    "### Note: Although I'm not doing any paramater tuning, I have Train, Validation, and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.1)\n",
    "\n",
    "X_train, y_train = df_train[\"text\"].to_numpy(), df_train[\"intents\"].to_numpy()\n",
    "X_val, y_val = df_val[\"text\"].to_numpy(), df_val[\"intents\"].to_numpy()\n",
    "X_test, y_test = df_test[\"text\"].to_numpy(), df_test[\"intents\"].to_numpy()\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "number_items = max(y_train_encoded) - min(y_train_encoded) + 1\n",
    "\n",
    "def get_one_hot(arr, number_items):\n",
    "    return tf.one_hot(arr, number_items)\n",
    "\n",
    "def get_labels_decoded(arr):\n",
    "    return label_encoder.inverse_transform(arr)\n",
    "\n",
    "y_train_one_hot = get_one_hot(y_train_encoded, number_items)\n",
    "y_val_one_hot = get_one_hot(y_val_encoded, number_items)\n",
    "y_test_one_hot = get_one_hot(y_test_encoded, number_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "- https://www.researchgate.net/publication/301932124_Intent_Classification_of_Short-Text_on_Social_Media\n",
    "- https://allennlp.org/ - [Deep contextualized word representations]. ELMo based embeddings \n",
    "\n",
    "## Word Embeddings\n",
    "- ELMo\n",
    "- BERT \n",
    "- USE\n",
    "GloVe: https://github.com/maciejkula/glove-python or SpaCy package implementation\n",
    "Word2Vec: gensim package implementation\n",
    "FastText: https://github.com/facebookresearch/fastText or gensim package implementation\n",
    "StarSpace: https://github.com/facebookresearch/StarSpace\n",
    "\n",
    "\n",
    "## Sentence Embeddings\n",
    "InferSent: https://github.com/facebookresearch/InferSent\n",
    "Sent2Vec: https://github.com/epfml/sent2vec\n",
    "Infersent performance: https://arxiv.org/pdf/1705.02364.pdf\n",
    "\n",
    "A good analysis of the different word embeddings/sentence embeddings is https://dspace.cvut.cz/bitstream/handle/10467/77029/F3-DP-2018-Brich-Tomas-Semantic_Sentence_Similarity_for_Intent_Recognition_Task.pdf?sequence=-1&isAllowed=y#ref%3Asec_is [\"Semantic Sentence Similarityfor Intent Recognition Task\"] says Sent2Vec is the best on benchmarks\n",
    "\n",
    "Another analysis https://arxiv.org/pdf/1806.06259.pdf [\"Evaluation of sentence embeddings in downstreamand linguistic probing tasks\". \n",
    "\n",
    "According to this a combo of Elmo+InferSent seems to be the best option.\n",
    "\n",
    "### Embedding Chosen\n",
    "\n",
    "Infersent or Elmo Seems to be the best option:\n",
    "Then classifiying intents, we may be given longer sentences, Inferset is known to have good performance https://arxiv.org/abg/abs/1705.02364 especiall on giving many correct results were retrieved in the top n, where n is an integer[\"Evaluation of sentence embeddings in downstream and linguistic probing tasks\"].  \n",
    "\n",
    "Elmo with allen should also be tested. \n",
    "\n",
    "## Model Chosen\n",
    "According to https://arxiv.org/abs/1705.02364[\"Supervised Learning of Universal Sentence Representations from Natural Language Inference Data\"] a BiDaf model works pretty well. Copied from https://github.com/rajatgermany/qa-nlp\n",
    "\n",
    "Other Models tested: Random Forest, Linear Regression, CNN. Since they were easy to add and test as a baseline\n",
    " \n",
    "https://arxiv.org/pdf/1207.0580.pdf - dropout after every layer\n",
    "\n",
    "### Open Source Classifiers tested\n",
    "- deeppavlov\n",
    "- allennlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt Deepalov\n",
    "# from deeppavlov import build_model, configs\n",
    "\n",
    "# model = build_model('sample_pavolv_config.json', download=True)  # in case of necessity to download some data\n",
    "# from deeppavlov import build_model, configs\n",
    "# print(configs.classifiers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Load model\n",
    "\n",
    "def generate_Infersent_model():\n",
    "    # Load model\n",
    "    model_version = 1\n",
    "    MODEL_PATH = \"encoder/infersent%s.pkl\" % model_version\n",
    "    params_model = {'bsize': 64, \n",
    "                    'word_emb_dim': 300, \n",
    "                    'enc_lstm_dim': 2048,\n",
    "                    'pool_type': 'max',\n",
    "                    'dpout_model': 0.0, \n",
    "                    'version': model_version}\n",
    "    model = InferSent(params_model)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "    W2V_PATH = 'GloVe/glove.840B.300d.txt'\n",
    "    model.set_w2v_path(W2V_PATH)\n",
    "\n",
    "    model.build_vocab_k_words(K=100000)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_doc2vec(text, model):\n",
    "    emb = model.encode(text, verbose=True)\n",
    "    return emb\n",
    "\n",
    "def generate_basic_fully_connected():\n",
    "    input_1 = Input((4096,), dtype=tf.float32)\n",
    "    x = Dense(2000, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(input_1)\n",
    "    \n",
    "    x = Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = Dense(450, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = Dense(250, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\n",
    "    out = Dense(222, activation='softmax')(x)\n",
    "    dual_model = Model(inputs=input_1, outputs=out)\n",
    "    \n",
    "    adamOpti = Adam()\n",
    "    dual_model.compile(optimizer=adamOpti, loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    dual_model.summary()\n",
    "    return dual_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "model = generate_Infersent_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bd94c287e24af882ed5f9cadfc5995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb words kept : 11/11 (100.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12de374f3de64cfa8734007f66f317b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speed : 4.8 sentences/s (cpu mode, bsize=64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.15559037,  0.01629045,  0.00050003, ...,  0.01910147,\n",
       "        -0.03814263,  0.05127323]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_doc2vec([\"Hello new world. How are you doing?\"], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edfdf629721469d9b608c7d5dd32534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb words kept : 6/6 (100.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c71f1807ea4ef3bf964dd7e12ccf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speed : 15.5 sentences/s (cpu mode, bsize=64)\n",
      "0.4536041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd478a780412420eb294177491b7ce65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb words kept : 6/6 (100.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f33f4d68084b478681d1903d9f2754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speed : 15.1 sentences/s (cpu mode, bsize=64)\n",
      "0.7514287\n"
     ]
    }
   ],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "res = get_doc2vec([\"happy\", \"running\"], model)\n",
    "print(cosine(res[0],res[1]))\n",
    "res = get_doc2vec([\"happy\", \"great\"], model)\n",
    "print(cosine(res[0],res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading X Train vec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17d4e3280af4dd9a0d7db424ab1f140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51972.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb words kept : 505444/516186 (97.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f6c00666734197a949eab3076d6d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=813.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speed : 133.7 sentences/s (cpu mode, bsize=64)\n",
      "loading X Val vec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792f39edcf6540eeb8e3e98cb9043859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5775.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb words kept : 56131/57329 (97.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3856d194c9b349b7b04da8a31f80adad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=91.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speed : 126.8 sentences/s (cpu mode, bsize=64)\n",
      "loading X Test vec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9adfa954e64a8192d62ae6693af4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6417.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb words kept : 62789/64137 (97.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f17a7a88824ea8bc5dfdd72057883e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=101.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speed : 122.2 sentences/s (cpu mode, bsize=64)\n"
     ]
    }
   ],
   "source": [
    "print(\"loading X Train vec\")\n",
    "X_train_vec = get_doc2vec(X_train, model)\n",
    "\n",
    "print(\"loading X Val vec\")\n",
    "X_val_vec = get_doc2vec(X_val, model)\n",
    "\n",
    "print(\"loading X Test vec\")\n",
    "X_test_vec = get_doc2vec(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "logs_base_dir = './logs'\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "logdir = os.path.join(logs_base_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs_base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 4096)]            0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 2000)              8194000   \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 450)               225450    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 250)               112750    \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 222)               55722     \n",
      "=================================================================\n",
      "Total params: 9,588,422\n",
      "Trainable params: 9,588,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 51972 samples, validate on 5775 samples\n",
      "Epoch 1/100\n",
      "51972/51972 [==============================] - 81s 2ms/sample - loss: 2.9199 - acc: 0.3898 - val_loss: 1.9007 - val_acc: 0.5699\n",
      "Epoch 2/100\n",
      "51972/51972 [==============================] - 83s 2ms/sample - loss: 1.7709 - acc: 0.6032 - val_loss: 1.4739 - val_acc: 0.6933\n",
      "Epoch 3/100\n",
      "51972/51972 [==============================] - 85s 2ms/sample - loss: 1.4913 - acc: 0.6793 - val_loss: 1.3125 - val_acc: 0.7332\n",
      "Epoch 4/100\n",
      "51972/51972 [==============================] - 83s 2ms/sample - loss: 1.3520 - acc: 0.7206 - val_loss: 1.2677 - val_acc: 0.7510\n",
      "Epoch 5/100\n",
      "51972/51972 [==============================] - 84s 2ms/sample - loss: 1.2561 - acc: 0.7436 - val_loss: 1.1961 - val_acc: 0.7687\n",
      "Epoch 6/100\n",
      "51972/51972 [==============================] - 87s 2ms/sample - loss: 1.2138 - acc: 0.7546 - val_loss: 1.1418 - val_acc: 0.7867\n",
      "Epoch 7/100\n",
      "51972/51972 [==============================] - 85s 2ms/sample - loss: 1.1590 - acc: 0.7711 - val_loss: 1.2028 - val_acc: 0.7737\n",
      "Epoch 8/100\n",
      "51972/51972 [==============================] - 84s 2ms/sample - loss: 1.1238 - acc: 0.7818 - val_loss: 1.1653 - val_acc: 0.7785\n",
      "Epoch 9/100\n",
      "51972/51972 [==============================] - 88s 2ms/sample - loss: 1.0900 - acc: 0.7911 - val_loss: 1.1356 - val_acc: 0.7841\n",
      "Epoch 10/100\n",
      "51972/51972 [==============================] - 84s 2ms/sample - loss: 1.0764 - acc: 0.7942 - val_loss: 1.1308 - val_acc: 0.7929\n",
      "Epoch 11/100\n",
      "51972/51972 [==============================] - 84s 2ms/sample - loss: 1.0574 - acc: 0.8011 - val_loss: 1.1129 - val_acc: 0.7903\n",
      "Epoch 12/100\n",
      "51972/51972 [==============================] - 85s 2ms/sample - loss: 1.0235 - acc: 0.8065 - val_loss: 1.0961 - val_acc: 0.7945\n",
      "Epoch 13/100\n",
      "51972/51972 [==============================] - 82s 2ms/sample - loss: 1.0336 - acc: 0.8043 - val_loss: 1.1208 - val_acc: 0.7898\n",
      "Epoch 14/100\n",
      "51972/51972 [==============================] - 87s 2ms/sample - loss: 0.9975 - acc: 0.8153 - val_loss: 1.1072 - val_acc: 0.7990\n",
      "Epoch 15/100\n",
      "51972/51972 [==============================] - 86s 2ms/sample - loss: 0.9761 - acc: 0.8194 - val_loss: 1.1071 - val_acc: 0.7986\n",
      "Epoch 16/100\n",
      "51972/51972 [==============================] - 86s 2ms/sample - loss: 0.9644 - acc: 0.8218 - val_loss: 1.0818 - val_acc: 0.8047\n",
      "Epoch 17/100\n",
      "51972/51972 [==============================] - 82s 2ms/sample - loss: 0.9609 - acc: 0.8205 - val_loss: 1.0907 - val_acc: 0.8066\n",
      "Epoch 18/100\n",
      "51972/51972 [==============================] - 86s 2ms/sample - loss: 0.9536 - acc: 0.8243 - val_loss: 1.1021 - val_acc: 0.8059\n",
      "Epoch 19/100\n",
      "51972/51972 [==============================] - 89s 2ms/sample - loss: 0.9405 - acc: 0.8267 - val_loss: 1.0657 - val_acc: 0.8043\n",
      "Epoch 20/100\n",
      "51972/51972 [==============================] - 95s 2ms/sample - loss: 0.9242 - acc: 0.8291 - val_loss: 1.1258 - val_acc: 0.7964\n",
      "Epoch 21/100\n",
      "51972/51972 [==============================] - 76s 1ms/sample - loss: 0.9167 - acc: 0.8305 - val_loss: 1.0879 - val_acc: 0.8028\n",
      "Epoch 22/100\n",
      "51972/51972 [==============================] - 72s 1ms/sample - loss: 0.9125 - acc: 0.8332 - val_loss: 1.1059 - val_acc: 0.8017\n",
      "Epoch 23/100\n",
      "51972/51972 [==============================] - 71s 1ms/sample - loss: 0.9020 - acc: 0.8351 - val_loss: 1.0701 - val_acc: 0.8076\n",
      "Epoch 24/100\n",
      "51972/51972 [==============================] - 72s 1ms/sample - loss: 0.9051 - acc: 0.8348 - val_loss: 1.0645 - val_acc: 0.8094\n",
      "Epoch 25/100\n",
      "51972/51972 [==============================] - 70s 1ms/sample - loss: 0.9010 - acc: 0.8358 - val_loss: 1.1514 - val_acc: 0.7941\n",
      "Epoch 26/100\n",
      "51972/51972 [==============================] - 70s 1ms/sample - loss: 0.8976 - acc: 0.8368 - val_loss: 1.0664 - val_acc: 0.8142\n",
      "Epoch 27/100\n",
      "51972/51972 [==============================] - 69s 1ms/sample - loss: 0.8748 - acc: 0.8424 - val_loss: 1.1244 - val_acc: 0.7952\n",
      "Epoch 28/100\n",
      "51972/51972 [==============================] - 69s 1ms/sample - loss: 0.8785 - acc: 0.8415 - val_loss: 1.1052 - val_acc: 0.8092\n",
      "Epoch 29/100\n",
      "51972/51972 [==============================] - 68s 1ms/sample - loss: 0.8730 - acc: 0.8429 - val_loss: 1.1204 - val_acc: 0.7938\n",
      "Epoch 30/100\n",
      "51972/51972 [==============================] - 68s 1ms/sample - loss: 0.8593 - acc: 0.8475 - val_loss: 1.1064 - val_acc: 0.8048\n",
      "Epoch 31/100\n",
      "51972/51972 [==============================] - 68s 1ms/sample - loss: 0.8857 - acc: 0.8399 - val_loss: 1.1177 - val_acc: 0.7988\n",
      "Epoch 32/100\n",
      "51972/51972 [==============================] - 69s 1ms/sample - loss: 0.8578 - acc: 0.8471 - val_loss: 1.0853 - val_acc: 0.8057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x161db4748>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffcc = generate_basic_fully_connected()\n",
    "ffcc.fit(X_train_vec, y_train_one_hot, \n",
    "         epochs=100, batch_size=64,\n",
    "         validation_data=[X_val_vec, y_val_one_hot]\n",
    "         , callbacks = [EarlyStopping(monitor='val_acc', patience=6), tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, X_vec, y_labels, nueral_net=True):\n",
    "    predictions = ffcc.predict(X_vec)\n",
    "    if nueral_net:\n",
    "        predicted_labels = get_labels_decoded(np.argmax(predictions, axis=1)) # each integer is [0, 0, 0,1]\n",
    "    else:\n",
    "        predicted_labels = get_labels_decoded(predictions)\n",
    "\n",
    "    correct = 0\n",
    "#     classification = {key:defaultdict(int) for key in y_labels}\n",
    "    classification = []\n",
    "    for pred,y_true in zip(predicted_labels,y_labels):\n",
    "        if pred == y_true:\n",
    "            correct += 1\n",
    "        classification.append({\"y_true\": y_true, \"pred\": pred})\n",
    "\n",
    "    classification = pd.DataFrame(classification)\n",
    "    classification = classification.groupby(['y_true','pred']).size().to_frame('count')\n",
    "    accuracy = correct/len(predictions)\n",
    "    \n",
    "    return accuracy, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.8921727083814361\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, train_classifications = calculate_accuracy(ffcc, X_train_vec, y_train)\n",
    "print(\"Train Accuracy\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_classifications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d3cd3d66bde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_classifications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_classifications' is not defined"
     ]
    }
   ],
   "source": [
    "train_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.78995670995671\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy, validation_classifications = calculate_accuracy(ffcc, X_val_vec, y_val)\n",
    "print(\"Validation Accuracy\", validation_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.7963222689730404\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, test_classifications = calculate_accuracy(ffcc, X_test_vec, y_test)\n",
    "print(\"Test Accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression \n",
    "Takes to long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_model = LogisticRegression(multi_class='multinomial', solver='newton-cg', verbose=1)\n",
    "# logistic_model.fit(X_train_vec, y_train_encoded)\n",
    "# TO slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_labels = get_labels_decoded(logistic_model.predict(X_train_vec))\n",
    "# print(\"Logistic regression Train Accuracy : \", metrics.accuracy_score(y_train, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bilstm():\n",
    "    input_1 = Input((4096,), dtype=tf.float32)\n",
    "    \n",
    "    questionEmbd = Embedding(input_dim=20000,\n",
    "                             mask_zero=False, \n",
    "                             trainable=False, output_dim=500)(input_1)\n",
    "    \n",
    "    bidirectional = Bidirectional(LSTM(300, return_sequences=True))(questionEmbd)\n",
    "    bidirectional_flatten = Flatten()(bidirectional)\n",
    "    \n",
    "    out = Dense(222,activation='sigmoid')(bidirectional_flatten)\n",
    "    dual_model = Model(inputs=input_1, outputs=out)\n",
    "    dual_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    dual_model.summary()\n",
    "    return dual_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bilstm = generate_bilstm()\n",
    "# bilstm.fit(X_train_vec, y_train_one_hot, epochs=10,batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_labels_decoded(y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
